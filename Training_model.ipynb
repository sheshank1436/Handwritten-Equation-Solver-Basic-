{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocr_data_extraction import data_conversion_to_array,load_data_from_csv\n",
    "from  ocr_network import network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the data from the folder , convert them to array by using the below function and load the output to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( folder has been converted to array\n",
      ") folder has been converted to array\n",
      "+ folder has been converted to array\n",
      "- folder has been converted to array\n",
      "0 folder has been converted to array\n",
      "1 folder has been converted to array\n",
      "2 folder has been converted to array\n",
      "3 folder has been converted to array\n",
      "4 folder has been converted to array\n",
      "5 folder has been converted to array\n",
      "6 folder has been converted to array\n",
      "7 folder has been converted to array\n",
      "8 folder has been converted to array\n",
      "9 folder has been converted to array\n",
      "times folder has been converted to array\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dic={'0':'0','1':'1','2':'2','3':'3','4':'4','5':'5','6':'6','7':'7','8':'8','9':'9','-':'10','+':'11','times':'12','(':'13',')':'14'}\n",
    "#folder where images are stored\n",
    "dir=r'hands_written\\write'\n",
    "data_conversion_to_array(dir,dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using the  csv file get input training data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,labels=load_data_from_csv(r'train_final.csv')\n",
    "#train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=network()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_conversion_to_required_array_dimensions(train_data,labels,num_classes):\n",
    "    input_data=[]\n",
    "    for i in range(train_data.shape[0]):\n",
    "        input_data.append(np.array(train_data[i:i+1]).reshape(28,28,1))\n",
    "    labels=np.array(labels)\n",
    "    labels=to_categorical(labels,num_classes)\n",
    "    return input_data,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data,labels=data_conversion_to_required_array_dimensions(train_data,labels,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(input_data,labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "699/699 [==============================] - 65s 93ms/step - loss: 1.0354 - accuracy: 0.7111 - val_loss: 0.2615 - val_accuracy: 0.9323\n",
      "Epoch 2/10\n",
      "699/699 [==============================] - 66s 95ms/step - loss: 0.3751 - accuracy: 0.8875 - val_loss: 0.1371 - val_accuracy: 0.9630\n",
      "Epoch 3/10\n",
      "699/699 [==============================] - 67s 96ms/step - loss: 0.2498 - accuracy: 0.9265 - val_loss: 0.0940 - val_accuracy: 0.9749\n",
      "Epoch 4/10\n",
      "699/699 [==============================] - 71s 101ms/step - loss: 0.1935 - accuracy: 0.9435 - val_loss: 0.0797 - val_accuracy: 0.9782\n",
      "Epoch 5/10\n",
      "699/699 [==============================] - 73s 104ms/step - loss: 0.1629 - accuracy: 0.9529 - val_loss: 0.0713 - val_accuracy: 0.9801\n",
      "Epoch 6/10\n",
      "699/699 [==============================] - 72s 103ms/step - loss: 0.1404 - accuracy: 0.9603 - val_loss: 0.0630 - val_accuracy: 0.9834\n",
      "Epoch 7/10\n",
      "699/699 [==============================] - 71s 102ms/step - loss: 0.1234 - accuracy: 0.9652 - val_loss: 0.0546 - val_accuracy: 0.9841\n",
      "Epoch 8/10\n",
      "699/699 [==============================] - 71s 101ms/step - loss: 0.1096 - accuracy: 0.9697 - val_loss: 0.0542 - val_accuracy: 0.9841\n",
      "Epoch 9/10\n",
      "699/699 [==============================] - 71s 101ms/step - loss: 0.1021 - accuracy: 0.9712 - val_loss: 0.0518 - val_accuracy: 0.9847\n",
      "Epoch 10/10\n",
      "699/699 [==============================] - 70s 100ms/step - loss: 0.0923 - accuracy: 0.9738 - val_loss: 0.0425 - val_accuracy: 0.9877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x183684044e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X_train),y_train, epochs=10, batch_size=200,shuffle=True,verbose=1,validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 4s 7ms/step - loss: 0.0447 - accuracy: 0.9870\n"
     ]
    }
   ],
   "source": [
    "model_evaluate=model.evaluate(np.array(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9869717359542847"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluate[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### storing the model into a jason file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(r\"model_final.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfx",
   "language": "python",
   "name": "tfx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
