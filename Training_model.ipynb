{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocr_data_extraction import data_conversion_to_array,load_data_from_csv\n",
    "from  ocr_network import network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the data from the folder , convert them to array by using the below function and load the output to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dic={'0':'0','1':'1','2':'2','3':'3','4':'4','5':'5','6':'6','7':'7','8':'8','9':'9','-':'10','+':'11','times':'12'}\n",
    "#folder where images are stored\n",
    "dir=r'hands_written\\write'\n",
    "data_conversion_to_array(dir,dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using the  csv file get input training data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,labels=load_data_from_csv(r'train_final.csv')\n",
    "#train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=network()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_conversion_to_required_array_dimensions(train_data,labels,num_classes):\n",
    "    input_data=[]\n",
    "    for i in range(train_data.shape[0]):\n",
    "        input_data.append(np.array(train_data[i:i+1]).reshape(28,28,1))\n",
    "    labels=np.array(labels)\n",
    "    labels=to_categorical(labels,num_classes)\n",
    "    return input_data,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data,labels=data_conversion_to_required_array_dimensions(train_data,labels,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(input_data,labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "516/516 [==============================] - 65s 126ms/step - loss: 1.5822 - accuracy: 0.5694 - val_loss: 0.7891 - val_accuracy: 0.7828\n",
      "Epoch 2/10\n",
      "516/516 [==============================] - 62s 121ms/step - loss: 0.8155 - accuracy: 0.7518 - val_loss: 0.2872 - val_accuracy: 0.9180\n",
      "Epoch 3/10\n",
      "516/516 [==============================] - 63s 121ms/step - loss: 0.3970 - accuracy: 0.8767 - val_loss: 0.1454 - val_accuracy: 0.9659\n",
      "Epoch 4/10\n",
      "516/516 [==============================] - 63s 122ms/step - loss: 0.2477 - accuracy: 0.9298 - val_loss: 0.0796 - val_accuracy: 0.9806\n",
      "Epoch 5/10\n",
      "516/516 [==============================] - 65s 125ms/step - loss: 0.1758 - accuracy: 0.9512 - val_loss: 0.0616 - val_accuracy: 0.9840\n",
      "Epoch 6/10\n",
      "516/516 [==============================] - 63s 122ms/step - loss: 0.1438 - accuracy: 0.9611 - val_loss: 0.0502 - val_accuracy: 0.9882\n",
      "Epoch 7/10\n",
      "516/516 [==============================] - 64s 124ms/step - loss: 0.1188 - accuracy: 0.9681 - val_loss: 0.0441 - val_accuracy: 0.9898\n",
      "Epoch 8/10\n",
      "516/516 [==============================] - 61s 119ms/step - loss: 0.1002 - accuracy: 0.9734 - val_loss: 0.0408 - val_accuracy: 0.9904\n",
      "Epoch 9/10\n",
      "516/516 [==============================] - 66s 128ms/step - loss: 0.0901 - accuracy: 0.9767 - val_loss: 0.0317 - val_accuracy: 0.9932\n",
      "Epoch 10/10\n",
      "516/516 [==============================] - 62s 121ms/step - loss: 0.0762 - accuracy: 0.9802 - val_loss: 0.0281 - val_accuracy: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e99eade6d8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X_train),y_train, epochs=10, batch_size=200,shuffle=True,verbose=1,validation_data=(np.array(X_test),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### storing the model into a jason file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(r\"model_final.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfx",
   "language": "python",
   "name": "tfx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
